name: "Master Scanning Pipeline"

on:
  workflow_dispatch:
    inputs:
      input_mode:
        description: "Input mode: single_domain, domain_list, or url_list"
        required: true
        type: choice
        options:
          - single_domain
          - domain_list
          - url_list
      targets:
        description: "Space-separated domains or URLs list (for url_list mode)"
        required: true
        type: string
      storage_repo:
        description: "SSH URL of private storage repository"
        required: true
        type: string
      custom_cookie:
        description: "Optional Cookie header"
        required: false
        type: string
        default: ""
      custom_header:
        description: "Optional extra header"
        required: false
        type: string
        default: ""
      run_x8:
        description: "Run x8 scanner?"
        required: false
        type: boolean
        default: true
      run_kxss:
        description: "Run kxss scanner?"
        required: false
        type: boolean
        default: true
      run_nuclei:
        description: "Run Nuclei scanner?"
        required: false
        type: boolean
        default: false
      run_dalfox:
        description: "Run Dalfox scanner?"
        required: false
        type: boolean
        default: false

jobs:
  # This setup job is the entry point for domain-based scans.
  # It creates a matrix of domains to be processed.
  setup-domain-matrix:
    runs-on: ubuntu-latest
    outputs:
      domains: ${{ steps.build-matrix.outputs.domains }}
    steps:
      - name: Build domains JSON array
        id: build-matrix
        run: |
          IFS=' ' read -r -a arr <<< "${{ github.event.inputs.targets }}"
          json=$(printf '%s\n' "${arr[@]}" | jq -R . | jq -s -c .)
          echo "domains=$json" >> $GITHUB_OUTPUT

  # Job 1: Gathers URLs for each domain and splits them into chunks.
  gather-and-split:
    name: Gather and Split URLs
    needs: setup-domain-matrix
    if: ${{ github.event.inputs.input_mode != 'url_list' }}
    runs-on: ubuntu-latest
    strategy:
      matrix:
        domain: ${{ fromJson(needs.setup-domain-matrix.outputs.domains) }}
    steps:
      - name: Install tools
        run: |
          sudo apt-get update
          sudo apt-get install -y git jq
          go install github.com/tomnomnom/waybackurls@latest
          go install github.com/lc/gau/v2/cmd/gau@latest
          go install github.com/tomnomnom/unfurl@latest
          echo "$(go env GOPATH)/bin" >> $GITHUB_PATH

      - name: Gather and Prepare URLs
        id: prep
        run: |
          set -e
          DOMAIN="${{ matrix.domain }}"
          URL_DIR="work/$DOMAIN"
          mkdir -p "$URL_DIR/chunks"

          echo "Gathering URLs for $DOMAIN..."
          echo "$DOMAIN" | waybackurls >> "$URL_DIR/raw.txt"
          echo "$DOMAIN" | gau >> "$URL_DIR/raw.txt"
          sort -u "$URL_DIR/raw.txt" > "$URL_DIR/urls.txt"

          echo "Extracting params and filtering static files..."
          cat "$URL_DIR/urls.txt" | unfurl keys | sort -u > "$URL_DIR/params.txt"
          grep -ivE "\\.(css|js|jpeg|jpg|png|gif|svg|ico|webp|pdf|mp4|mp3|eot|woff|woff2|ttf)(\\?.*)?$" "$URL_DIR/urls.txt" > "$URL_DIR/non-static-urls.txt"

          echo "Splitting non-static URLs into chunks..."
          split -l 500 "$URL_DIR/non-static-urls.txt" "$URL_DIR/chunks/chunk_"

          echo "url_dir=$URL_DIR" >> $GITHUB_OUTPUT

      - name: Upload domain work directory
        uses: actions/upload-artifact@v4
        with:
          name: work-${{ matrix.domain }}
          path: ${{ steps.prep.outputs.url_dir }}

  # Job 2: Runs httpx in parallel on the URL chunks.
  parallel-httpx:
    name: Parallel httpx Scan
    needs: [gather-and-split, setup-domain-matrix]
    runs-on: ubuntu-latest
    strategy:
      matrix:
        domain: ${{ fromJson(needs.setup-domain-matrix.outputs.domains) }}
      max-parallel: 20
    steps:
      - name: Install httpx
        run: go install github.com/projectdiscovery/httpx/cmd/httpx@latest && echo "$(go env GOPATH)/bin" >> $GITHUB_PATH

      - name: Download domain work directory
        uses: actions/download-artifact@v4
        with:
          name: work-${{ matrix.domain }}
          path: work/${{ matrix.domain }}

      - name: Run httpx on all chunks
        id: httpx
        run: |
          set -e
          CHUNK_DIR="work/${{ matrix.domain }}/chunks"
          LIVE_URLS_FILE="work/${{ matrix.domain }}/live-urls.txt"
          find "$CHUNK_DIR" -type f -name "chunk_*" | xargs -P 10 -I {} cat {} | httpx -silent -threads 50 -timeout 10 -retries 2 -follow-redirects > "$LIVE_URLS_FILE"
          echo "live_urls_file=$LIVE_URLS_FILE" >> $GITHUB_OUTPUT

      - name: Upload httpx results
        uses: actions/upload-artifact@v4
        with:
          name: httpx-results-${{ matrix.domain }}
          path: ${{ steps.httpx.outputs.live_urls_file }}

  # Job 3: Collects results, commits them, and triggers downstream scanners.
  collect-and-trigger:
    name: Collect and Trigger
    needs: [parallel-httpx, setup-domain-matrix]
    runs-on: ubuntu-latest
    strategy:
      matrix:
        domain: ${{ fromJson(needs.setup-domain-matrix.outputs.domains) }}
    env:
      STORAGE_REPO: ${{ github.event.inputs.storage_repo }}
      COOKIE: ${{ github.event.inputs.custom_cookie }}
      HEADER: ${{ github.event.inputs.custom_header }}
    steps:
      - name: Download domain work directory
        uses: actions/download-artifact@v4
        with:
          name: work-${{ matrix.domain }}
          path: work/${{ matrix.domain }}

      - name: Download httpx results
        uses: actions/download-artifact@v4
        with:
          name: httpx-results-${{ matrix.domain }}
          path: work/${{ matrix.domain }}

      - name: Commit discovery results
        env:
          DEPLOY_KEY: ${{ secrets.DEPLOY_KEY }}
        run: |
          mkdir -p ~/.ssh
          echo "$DEPLOY_KEY" > ~/.ssh/id_rsa
          chmod 600 ~/.ssh/id_rsa
          ssh-keyscan github.com >> ~/.ssh/known_hosts
          git clone "$STORAGE_REPO" storage

          DOMAIN="${{ matrix.domain }}"
          mkdir -p "storage/$DOMAIN/discovery"
          cp "work/$DOMAIN/live-urls.txt" "storage/$DOMAIN/discovery/live-urls.txt"
          cp "work/$DOMAIN/params.txt"     "storage/$DOMAIN/discovery/params.txt"

          cd storage
          git config user.name "GitHub Actions"
          git config user.email "actions@github.com"
          if ! git diff --quiet; then
            git add .
            git commit -m "Discovery for $DOMAIN" || echo "No changes"
            git push
          else
            echo "No changes to commit"
          fi

      - name: Trigger Scanners
        env:
          GH_PAT: ${{ secrets.GH_PAT }}
        run: |
          DOMAIN="${{ matrix.domain }}"
          # Trigger x8 & kxss
          if [[ "${{ github.event.inputs.run_x8 }}" == "true" || "${{ github.event.inputs.run_kxss }}" == "true" ]]; then
            curl -s -X POST -H "Authorization: token $GH_PAT" -H "Accept: application/vnd.github.v3+json" \
            https://api.github.com/repos/bigidavii/Xss-Scanner/actions/workflows/x8-kxss-workflow.yaml/dispatches \
            -d '{
              "ref": "main",
              "inputs": {
                "target_name": "'"$DOMAIN"'",
                "storage_repo": "'"$STORAGE_REPO"'",
                "custom_cookie": "'"$COOKIE"'",
                "custom_header": "'"$HEADER"'",
                "run_x8": ${{ github.event.inputs.run_x8 }},
                "run_kxss": ${{ github.event.inputs.run_kxss }}
              }
            }'
          fi
          # Trigger Dalfox
          if [[ "${{ github.event.inputs.run_dalfox }}" == "true" ]]; then
            curl -s -X POST -H "Authorization: token $GH_PAT" -H "Accept: application/vnd.github.v3+json" \
            https://api.github.com/repos/mamadzht-max/Dalfox-Scanner/actions/workflows/dalfox-scanner.yml/dispatches \
            -d '{
              "ref": "main",
              "inputs": {
                "target_name": "'"$DOMAIN"'",
                "storage_repo": "'"$STORAGE_REPO"'",
                "custom_cookie": "'"$COOKIE"'",
                "custom_header": "'"$HEADER"'"
              }
            }'
          fi
          # Trigger Nuclei
          if [[ "${{ github.event.inputs.run_nuclei }}" == "true" ]]; then
            curl -s -X POST -H "Authorization: token $GH_PAT" -H "Accept: application/vnd.github.v3+json" \
            https://api.github.com/repos/ACCOUNT3/Nuclei-Scanner/actions/workflows/nuclei-workflow-template.yaml/dispatches \
            -d '{
              "ref": "main",
              "inputs": {
                "target_name": "'"$DOMAIN"'",
                "storage_repo": "'"$STORAGE_REPO"'"
              }
            }'
          fi

  # The legacy url_list mode remains unchanged.
  url-gathering-legacy:
    name: URL Gathering (legacy)
    if: ${{ github.event.inputs.input_mode == 'url_list' }}
    runs-on: ubuntu-latest
    steps:
      - name: Build URL list
        run: |
          mkdir -p work
          echo "${{ github.event.inputs.targets }}" | tr ' ' '\n' > work/urls.txt
      - name: Upload raw URLs
        uses: actions/upload-artifact@v4
        with:
          name: raw-urls
          path: work/urls.txt

  probe-and-filter-legacy:
    name: Probe & Filter URLs (legacy)
    needs: url-gathering-legacy
    if: ${{ github.event.inputs.input_mode == 'url_list' }}
    runs-on: ubuntu-latest
    steps:
      - name: Download raw URLs
        uses: actions/download-artifact@v4
        with:
          name: raw-urls
          path: work
      - name: Install tools
        run: |
          sudo apt-get update
          sudo apt-get install -y jq
          go install github.com/projectdiscovery/httpx/cmd/httpx@latest
          go install github.com/tomnomnom/unfurl@latest
          echo "$(go env GOPATH)/bin" >> $GITHUB_PATH
      - name: Filter live URLs
        run: |
          mkdir -p work/filtered
          cat work/urls.txt | httpx -silent -threads 50 > work/filtered/live-urls.txt
      - name: Extract parameters
        run: |
          cat work/urls.txt | unfurl querystring keys | sort -u > work/filtered/params.txt
      - name: Upload filtered results
        uses: actions/upload-artifact@v4
        with:
          name: filtered-urls
          path: work/filtered

  commit-results-legacy:
    name: Commit Legacy Results
    needs: probe-and-filter-legacy
    if: ${{ github.event.inputs.input_mode == 'url_list' }}
    runs-on: ubuntu-latest
    steps:
      - name: Compute target name
        id: tgt
        run: |
          echo "TARGET_NAME=url_list_${{ github.run_id }}" >> $GITHUB_OUTPUT
          echo "echo ${TARGET_NAME}"
      - name: Setup SSH
        env:
          DEPLOY_KEY: ${{ secrets.DEPLOY_KEY }}
        run: |
          mkdir -p ~/.ssh
          echo "$DEPLOY_KEY" > ~/.ssh/id_rsa
          chmod 600 ~/.ssh/id_rsa
          ssh-keyscan github.com >> ~/.ssh/known_hosts
      - name: Clone storage repo
        run: |
          git clone "${{ github.event.inputs.storage_repo }}" storage
      - name: Download filtered results
        uses: actions/download-artifact@v4
        with:
          name: filtered-urls
          path: work/filtered
      - name: Copy to storage
        run: |
          mkdir -p storage/${{ steps.tgt.outputs.TARGET_NAME }}/discovery
          cp work/filtered/live-urls.txt storage/${{ steps.tgt.outputs.TARGET_NAME }}/discovery/live-urls.txt
          cp work/filtered/params.txt     storage/${{ steps.tgt.outputs.TARGET_NAME }}/discovery/params.txt
      - name: Commit & push
        run: |
          cd storage
          git config user.name "GitHub Actions"
          git config user.email "actions@github.com"
          git add .
          git commit -m "Legacy URL-list discovery: ${{ steps.tgt.outputs.TARGET_NAME }}" || echo "No changes"
          git push

  trigger-scanners-legacy:
    name: Trigger Scanners (legacy)
    needs: commit-results-legacy
    if: ${{ github.event.inputs.input_mode == 'url_list' }}
    runs-on: ubuntu-latest
    env:
      GH_PAT: ${{ secrets.GH_PAT }}
    steps:
      - name: Trigger Scanners
        run: |
          TARGET_NAME="url_list_${{ github.run_id }}"
          # Trigger x8 & kxss
          if [[ "${{ github.event.inputs.run_x8 }}" == "true" || "${{ github.event.inputs.run_kxss }}" == "true" ]]; then
            curl -s -X POST -H "Authorization: token $GH_PAT" -H "Accept: application/vnd.github.v3+json" \
            https://api.github.com/repos/bigidavii/Xss-Scanner/actions/workflows/x8-kxss-workflow.yaml/dispatches \
            -d '{
              "ref": "main",
              "inputs": {
                "target_name": "'"$TARGET_NAME"'",
                "storage_repo": "'"${{ github.event.inputs.storage_repo }}"'",
                "custom_cookie": "'"${{ github.event.inputs.custom_cookie }}"'",
                "custom_header": "'"${{ github.event.inputs.custom_header }}"'",
                "run_x8": ${{ github.event.inputs.run_x8 }},
                "run_kxss": ${{ github.event.inputs.run_kxss }}
              }
            }'
          fi
          # Trigger Dalfox
          if [[ "${{ github.event.inputs.run_dalfox }}" == "true" ]]; then
            curl -s -X POST -H "Authorization: token $GH_PAT" -H "Accept: application/vnd.github.v3+json" \
            https://api.github.com/repos/mamadzht-max/Dalfox-Scanner/actions/workflows/dalfox-scanner.yml/dispatches \
            -d '{
              "ref": "main",
              "inputs": {
                "target_name": "'"$TARGET_NAME"'",
                "storage_repo": "'"${{ github.event.inputs.storage_repo }}"'",
                "custom_cookie": "'"${{ github.event.inputs.custom_cookie }}"'",
                "custom_header": "'"${{ github.event.inputs.custom_header }}"'"
              }
            }'
          fi
          # Trigger Nuclei
          if [[ "${{ github.event.inputs.run_nuclei }}" == "true" ]]; then
            curl -s -X POST -H "Authorization: token $GH_PAT" -H "Accept: application/vnd.github.v3+json" \
            https://api.github.com/repos/ACCOUNT3/Nuclei-Scanner/actions/workflows/nuclei-workflow-template.yaml/dispatches \
            -d '{
              "ref": "main",
              "inputs": {
                "target_name": "'"$TARGET_NAME"'",
                "storage_repo": "'"${{ github.event.inputs.storage_repo }}"'"
              }
            }'
          fi
